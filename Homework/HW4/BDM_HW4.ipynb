{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rtree\n",
    "import time\n",
    "from pyspark import SparkContext\n",
    "from geopandas import GeoDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gzip\n",
    "# import shutil\n",
    "# with gzip.open('yellow.csv.gz', 'rb') as f_in:\n",
    "#     with open('yellow.csv', 'wb') as f_out:\n",
    "#         shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genIndex(shapefile):\n",
    "    import rtree\n",
    "    import fiona.crs\n",
    "    import geopandas as gpd\n",
    "    zones = gpd.read_file(shapefile).to_crs(fiona.crs.from_epsg(2263))\n",
    "    index = rtree.Rtree()\n",
    "    for idx, geometry in enumerate(zones.geometry):\n",
    "        yield (idx, geometry.bounds, zones.iloc[idx])\n",
    "\n",
    "def getZone(p, index, field):\n",
    "    matches = index.intersection((p.x, p.y, p.x, p.y), objects=True)\n",
    "    for match in matches:\n",
    "        hood = match.object\n",
    "        if hood.geometry.contains(p):\n",
    "            return hood[field]\n",
    "    return None\n",
    "        \n",
    "def createIndex(shapefile):\n",
    "    import rtree\n",
    "    import fiona.crs\n",
    "    import geopandas as gpd\n",
    "    zones = gpd.read_file(shapefile).to_crs(fiona.crs.from_epsg(2263))\n",
    "    index = rtree.Rtree()\n",
    "    for idx, geometry in enumerate(zones.geometry):\n",
    "        index.insert(idx, geometry.bounds)\n",
    "    return {\"index\": index, \"zones\": zones}\n",
    "\n",
    "def findZone(p, geo_map):\n",
    "    match = geo_map['index'].intersection((p.x, p.y, p.x, p.y))\n",
    "    for idx in match:\n",
    "        if geo_map['zones'].geometry[idx].contains(p):\n",
    "            return idx\n",
    "    return None\n",
    "\n",
    "def processTrips(pid, records):\n",
    "    import csv\n",
    "    import pyproj\n",
    "    import shapely.geometry as geom\n",
    "    import rtree\n",
    "\n",
    "    # Skip the header\n",
    "    if pid==0:\n",
    "        next(records)\n",
    "    \n",
    "    reader = csv.reader(records)\n",
    "    \n",
    "    # Create an R-tree index\n",
    "    proj = pyproj.Proj(init=\"epsg:2263\", preserve_units=True)    \n",
    "#     boros = createIndex('boroughs.geojson')    \n",
    "#     neighborhoods = createIndex('neighborhoods.geojson')  \n",
    "    boros_index = rtree.index.Index(genIndex('boroughs.geojson'))\n",
    "    hood_index = rtree.index.Index(genIndex('neighborhoods.geojson'))\n",
    "\n",
    "    for row in reader:\n",
    "        # 'tpep_pickup_datetime,tpep_dropoff_datetime,pickup_latitude,pickup_longitude,dropoff_latitude,dropoff_longitude',\n",
    "        try: \n",
    "            if 'NULL' in row[2:5]: \n",
    "                continue\n",
    "            pickup_point = geom.Point(proj(float(row[3]), float(row[2])))\n",
    "#             start_boro = findZone(pickup_point, boros)\n",
    "            start_boro = getZone(pickup_point, boros_index, 'boroname')\n",
    "\n",
    "            if start_boro:\n",
    "                dropoff_point= geom.Point(proj(float(row[5]), float(row[4])))\n",
    "#                 end_hood = findZone(dropoff_point, neighborhoods)\n",
    "                end_hood = getZone(dropoff_point, hood_index, 'neighborhood')\n",
    "                if end_hood:\n",
    "#                     boro_name = boros['zones'].iloc[start_boro]['boroname']\n",
    "#                     hood_name = neighborhoods['zones'].iloc[end_hood]['neighborhood']\n",
    "                    yield ( (start_boro, end_hood), 1 )\n",
    "        except: \n",
    "            print(\"Failed at: \", row) ##TODO this won't log anything\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_partition(row):\n",
    "    if row[0][0] == 'Manhattan':\n",
    "        return 0\n",
    "    if row[0][0] == 'Brooklyn':\n",
    "        return 1\n",
    "    if row[0][0] == 'Queens':\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "def run_spark(taxi_file, sc):\n",
    "    from heapq import nlargest\n",
    "    from operator import itemgetter\n",
    "\n",
    "    start = time.time()\n",
    "    rdd = sc.textFile(taxi_file).mapPartitionsWithIndex(processTrips)\n",
    "    \n",
    "    counts = rdd.reduceByKey(lambda x,y: x+y) \\\n",
    "                .map(lambda x: ( x[0][0], [(x[0][1], x[1])] ) ) \\\n",
    "                .reduceByKey(lambda x,y: x+y) \\\n",
    "                .mapValues(lambda hood_counts: nlargest(3, hood_counts, key=itemgetter(1))) \\\n",
    "                .map(lambda x: str(x[0]) + \",\" + \",\".join([str(i) for sub in x[1] for i in sub])) \\\n",
    "                .collect()\n",
    "    \n",
    "    counts.sort()\n",
    "    return counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitions:  2\n",
      "Partitions:  4\n",
      "['Brooklyn,Clinton Hill,1,Boerum Hill,1,Prospect Heights,1', 'Manhattan,Upper West Side,14,Chelsea,10,Midtown,9', \"Queens,Astoria,3,Hell's Kitchen,1\"]\n",
      "Execution Time(secs):  59.24747133255005\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(run_spark('yellow100.csv', sc))\n",
    "print(\"Execution Time(secs): \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitions:  2\n",
      "Partitions:  4\n",
      "['Brooklyn,Bushwick,2,Clinton Hill,1,Boerum Hill,1', 'Manhattan,Chelsea,27,Upper West Side,23,Upper East Side,22', \"Queens,Astoria,3,LaGuardia Airport,1,Hell's Kitchen,1\"]\n",
      "Execution Time(secs):  65.58607077598572\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(run_spark('yellow250.csv', sc))\n",
    "print(\"Execution Time(secs): \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitions:  2\n",
      "Partitions:  4\n",
      "['Brooklyn,Williamsburg,3,Bushwick,3,Crown Heights,2', 'Manhattan,Upper East Side,51,Chelsea,45,Midtown,43', 'Queens,Astoria,3,Long Island City,2,LaGuardia Airport,1']\n",
      "Execution Time(secs):  60.23847579956055\n"
     ]
    }
   ],
   "source": [
    "# Brooklyn,Bushwick,3,Williamsburg,3,Crown Heights,2', 'Manhattan,Upper East Side,51,Chelsea,45,Midtown,43', \n",
    "# 'Queens,Astoria,3,Long Island City,2,LaGuardia Airport,1'\n",
    "start = time.time()\n",
    "print(run_spark('yellow500.csv', sc))\n",
    "print(\"Execution Time(secs): \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Brooklyn,Williamsburg,8,Bushwick,7,Clinton Hill,4', 'Manhattan,Upper East Side,108,Midtown,92,Chelsea,86', 'Queens,Astoria,5,Upper East Side,2,Upper West Side,2']\n",
      "Execution Time(secs):  50.558775424957275\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(run_spark('yellow1000.csv', sc))\n",
    "print(\"Execution Time(secs): \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bronx,Harlem,50,Longwood,49,East Harlem,32', 'Brooklyn,Williamsburg,1880,Bedford-Stuyvesant,983,Greenpoint,730', 'Manhattan,Upper East Side,52860,Midtown,46448,Upper West Side,36754', 'Queens,Midtown,1910,Upper East Side,1231,Astoria,1084', \"Staten Island,Castleton Corners,2,West Brighton,1,Bull's Head,1\"]\n",
      "Execution Time(secs):  1732.6583473682404\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(run_spark('yellow.csv', sc))\n",
    "print(\"Execution Time(secs): \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{project}\".format(project=\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
