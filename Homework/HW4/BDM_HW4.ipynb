{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rtree\n",
    "import time\n",
    "from pyspark import SparkContext\n",
    "from geopandas import GeoDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gzip\n",
    "# import shutil\n",
    "# with gzip.open('yellow.csv.gz', 'rb') as f_in:\n",
    "#     with open('yellow.csv', 'wb') as f_out:\n",
    "#         shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def createIndex(shapefile):\n",
    "    import rtree\n",
    "    import fiona.crs\n",
    "    import geopandas as gpd\n",
    "    zones = gpd.read_file(shapefile).to_crs(fiona.crs.from_epsg(2263))\n",
    "    index = rtree.Rtree()\n",
    "    for idx,geometry in enumerate(zones.geometry):\n",
    "        index.insert(idx, geometry.bounds)\n",
    "    return {\"index\": index, \"zones\": zones}\n",
    "\n",
    "def findZone(p, geo_map):\n",
    "    match = geo_map['index'].intersection((p.x, p.y, p.x, p.y))\n",
    "    for idx in match:\n",
    "        if geo_map['zones'].geometry[idx].contains(p):\n",
    "            return idx\n",
    "    return None\n",
    "\n",
    "def processTrips(pid, records):\n",
    "    import csv\n",
    "    import pyproj\n",
    "    import shapely.geometry as geom\n",
    "\n",
    "    # Skip the header\n",
    "    if pid==0:\n",
    "        next(records)\n",
    "    \n",
    "    reader = csv.reader(records)\n",
    "    counts = {}\n",
    "    \n",
    "    # Create an R-tree index\n",
    "    proj = pyproj.Proj(init=\"epsg:2263\", preserve_units=True)    \n",
    "    boros = createIndex('boroughs.geojson')    \n",
    "    neighborhoods = createIndex('neighborhoods.geojson')    \n",
    "    \n",
    "    for row in reader:\n",
    "        # 'tpep_pickup_datetime,tpep_dropoff_datetime,pickup_latitude,pickup_longitude,dropoff_latitude,dropoff_longitude',\n",
    "        try: \n",
    "            if 'NULL' in row[2:5]: \n",
    "                continue\n",
    "            pickup_point = geom.Point(proj(float(row[3]), float(row[2])))\n",
    "            start_boro = findZone(pickup_point, boros)\n",
    "            \n",
    "            if start_boro:\n",
    "                boro_name = boros['zones'].iloc[start_boro]['boroname']\n",
    "\n",
    "                dropoff_point= geom.Point(proj(float(row[5]), float(row[4])))\n",
    "                end_hood = findZone(dropoff_point, neighborhoods)\n",
    "                if end_hood:\n",
    "                    hood_name = neighborhoods['zones'].iloc[end_hood]['neighborhood']\n",
    "                    yield ( (boro_name, hood_name), 1 )\n",
    "        except: \n",
    "            print(\"Failed at: \", row) ##TODO this won't log anything\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_spark(taxi_file, sc):\n",
    "    from heapq import nlargest\n",
    "    from operator import itemgetter\n",
    "\n",
    "    start = time.time()\n",
    "    rdd = sc.textFile(taxi_file).mapPartitionsWithIndex(processTrips).cache()\n",
    "    \n",
    "    counts = rdd.reduceByKey(lambda x,y: x+y) \\\n",
    "                .map(lambda x: ( x[0][0], [(x[0][1], x[1])] ) ) \\\n",
    "                .reduceByKey(lambda x,y: x+y) \\\n",
    "                .mapValues(lambda hood_counts: nlargest(3, hood_counts, key=itemgetter(1))) \\\n",
    "                .map(lambda x: x[0]+ \",\" + \",\".join([str(i) for sub in x[1] for i in sub])) \\\n",
    "                .collect()\n",
    "    \n",
    "    counts.sort()\n",
    "    return counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Brooklyn,Bushwick,3,Williamsburg,3,Crown Heights,2', 'Manhattan,Upper East Side,51,Chelsea,47,Midtown,44', 'Queens,Astoria,3,Long Island City,2,LaGuardia Airport,1']\n",
      "Execution Time(secs):  136.868812084198\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(run_spark('yellow.csv', sc))\n",
    "print(\"Execution Time(secs): \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
