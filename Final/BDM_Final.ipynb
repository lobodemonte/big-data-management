{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import traceback\n",
    "import time\n",
    "\n",
    "from datetime import datetime\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf, array, count\n",
    "from pyspark.sql.functions import broadcast,coalesce, lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sc = SparkContext()\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "streets = \"nyc_cscl.csv\"\n",
    "violations = \"nyc_parking_violation/*.csv\"\n",
    "\n",
    "#streets = \"hdfs:///tmp/bdm/nyc_cscl.csv\"\n",
    "#violations = \"hdfs:///tmp/bdm/nyc_parking_violation/*.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       1.000\n",
      "Model:                            OLS   Adj. R-squared:                  1.000\n",
      "Method:                 Least Squares   F-statistic:                 1.161e+30\n",
      "Date:                Sat, 16 May 2020   Prob (F-statistic):           1.76e-45\n",
      "Time:                        10:37:56   Log-Likelihood:                 138.47\n",
      "No. Observations:                   5   AIC:                            -272.9\n",
      "Df Residuals:                       3   BIC:                            -273.7\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       1000.0000   2.27e-13    4.4e+15      0.000    1000.000    1000.000\n",
      "x1          -100.0000   9.28e-14  -1.08e+15      0.000    -100.000    -100.000\n",
      "==============================================================================\n",
      "Omnibus:                          nan   Durbin-Watson:                   0.000\n",
      "Prob(Omnibus):                    nan   Jarque-Bera (JB):                1.875\n",
      "Skew:                           0.000   Prob(JB):                        0.392\n",
      "Kurtosis:                       0.000   Cond. No.                         4.74\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erikl\\Anaconda2\\envs\\AppliedDataScience\\lib\\site-packages\\statsmodels\\stats\\stattools.py:71: ValueWarning: omni_normtest is not valid with less than 8 observations; 5 samples were given.\n",
      "  \"samples were given.\" % int(n), ValueWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "999.9999999999998"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_upper(string):\n",
    "    if string is not None:\n",
    "        return string.strip().upper()\n",
    "    return None\n",
    "\n",
    "def get_county_code(county):\n",
    "    if county is not None:\n",
    "        # Boro codes: 1 = MN, 2 = BX, 3 = BK, 4 = QN, 5 = SI\n",
    "        if county.startswith(\"M\") or county.startswith(\"N\"):\n",
    "            return 1\n",
    "        if county in ['BRONX', 'BX', 'PBX']:\n",
    "            return 2\n",
    "        if county in ['BK', 'K', 'KING', 'KINGS']:\n",
    "            return 3\n",
    "        if county.startswith('Q'):\n",
    "            return 4\n",
    "        if county == 'R' or county == 'ST':\n",
    "            return 5\n",
    "    return None\n",
    "\n",
    "def get_year(date_string):\n",
    "    if date_string is not None:\n",
    "        data_val = datetime.strptime(date_string.strip(), '%m/%d/%Y')    \n",
    "        return data_val.year\n",
    "    return None\n",
    "\n",
    "def get_street_number(street_val):\n",
    "    if street_val is not None:\n",
    "        if type(street_val) is int:\n",
    "            return street_val\n",
    "        elems = street_val.split(\"-\")  \n",
    "        if len(elems) == 1 and elems[0].isdigit():\n",
    "            return int(elems[0])\n",
    "        elif len(elems) == 2 and elems[0].isdigit() and elems[1].isdigit():\n",
    "            new_val = elems[0] + \"{:04d}\".format(int(elems[1]))\n",
    "            if new_val.isdigit():\n",
    "                return int(new_val)          \n",
    "        else:\n",
    "            new_val = \"\".join(elems)\n",
    "            if new_val.isdigit():\n",
    "                return int(new_val)\n",
    "    return 0\n",
    "\n",
    "def as_digit(val):\n",
    "    if val:\n",
    "        return int(val)\n",
    "    return val\n",
    "\n",
    "def getOLS(values):\n",
    "    import statsmodels.api as sm\n",
    "    X = sm.add_constant([0,1,2,3,4])\n",
    "    fit = sm.OLS(values, X).fit()\n",
    "    coef = fit.params[0]\n",
    "    print(fit.summary())\n",
    "    return float(coef)\n",
    "\n",
    "getOLS([1000,900,800,700,600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_violations_df(violations_file, spark):\n",
    "    get_county_code_udf = udf(get_county_code)\n",
    "    get_street_number_udf = udf(get_street_number)\n",
    "    get_year_udf = udf(get_year)\n",
    "    to_upper_udf = udf(to_upper)\n",
    "    \n",
    "    violations_df = spark.read.csv(violations_file, header=True, inferSchema=True)\n",
    "\n",
    "    violations_df = violations_df.select(\"Violation County\", \"House Number\", \"Street Name\", \"Issue Date\")\n",
    "\n",
    "    violations_df = violations_df.withColumnRenamed(\"Violation County\",\"COUNTY\")\n",
    "    violations_df = violations_df.withColumnRenamed(\"House Number\",\"HOUSENUM\")\n",
    "    violations_df = violations_df.withColumnRenamed(\"Street Name\",\"STREETNAME\")\n",
    "    violations_df = violations_df.withColumnRenamed(\"Issue Date\",\"YEAR\")\n",
    "    \n",
    "    violations_df = violations_df.withColumn('COUNTY', get_county_code_udf(violations_df['COUNTY']))\n",
    "    violations_df = violations_df.withColumn('HOUSENUM', get_street_number_udf(violations_df['HOUSENUM']))\n",
    "    violations_df = violations_df.withColumn('STREETNAME', to_upper_udf(violations_df['STREETNAME']))\n",
    "    violations_df = violations_df.withColumn('YEAR', get_year_udf(violations_df['YEAR']))\n",
    "\n",
    "    violations_df = violations_df.filter((violations_df['COUNTY'].isNotNull()) \n",
    "                                         & (violations_df['HOUSENUM'].isNotNull()) \n",
    "                                         & (violations_df['STREETNAME'].isNotNull()) \n",
    "                                         & (violations_df['YEAR'].isNotNull())\n",
    "                                        )\n",
    "    \n",
    "    violations_df = violations_df.withColumn(\"COUNTY\", violations_df[\"COUNTY\"].cast(\"integer\"))\n",
    "    violations_df = violations_df.withColumn(\"HOUSENUM\", violations_df[\"HOUSENUM\"].cast(\"integer\"))\n",
    "    violations_df = violations_df.withColumn(\"YEAR\", violations_df[\"YEAR\"].cast(\"integer\"))\n",
    "\n",
    "    \n",
    "    violations_df = violations_df.where(violations_df.YEAR.isin(list(range(2015,2020))))\n",
    "    violations_df = violations_df.repartition(5,'COUNTY')\n",
    "    violations_df = violations_df.alias('v')\n",
    "    return violations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_streets_df(streets_file, spark):\n",
    "    get_street_number_udf = udf(get_street_number)\n",
    "    to_upper_udf = udf(to_upper)\n",
    "    as_digit_udf = udf(as_digit)\n",
    "    \n",
    "    streets_df = spark.read.csv(streets_file, header=True, inferSchema=True)\n",
    "\n",
    "    streets_df = streets_df.select(\"PHYSICALID\",\"BOROCODE\", \"FULL_STREE\", \"ST_LABEL\",\"L_LOW_HN\", \"L_HIGH_HN\", \n",
    "                                   \"R_LOW_HN\", \"R_HIGH_HN\")\n",
    "\n",
    "    streets_df = streets_df.withColumnRenamed(\"L_LOW_HN\",\"OddLo\")\n",
    "    streets_df = streets_df.withColumnRenamed(\"L_HIGH_HN\",\"OddHi\")\n",
    "    streets_df = streets_df.withColumnRenamed(\"R_LOW_HN\",\"EvenLo\")\n",
    "    streets_df = streets_df.withColumnRenamed(\"R_HIGH_HN\",\"EvenHi\")\n",
    "    \n",
    "    streets_df = streets_df.filter((streets_df['BOROCODE'].isNotNull()) & (streets_df['PHYSICALID'].isNotNull()))\n",
    "    \n",
    "    streets_df = streets_df.withColumn('BOROCODE', as_digit_udf(streets_df['BOROCODE']))\n",
    "    streets_df = streets_df.withColumn('FULL_STREE', to_upper_udf(streets_df['FULL_STREE']))\n",
    "    streets_df = streets_df.withColumn('ST_LABEL',   to_upper_udf(streets_df['ST_LABEL']))\n",
    "    streets_df = streets_df.withColumn('OddLo', get_street_number_udf(streets_df['OddLo']))\n",
    "    streets_df = streets_df.withColumn('OddHi', get_street_number_udf(streets_df['OddHi']))\n",
    "    streets_df = streets_df.withColumn('EvenLo', get_street_number_udf(streets_df['EvenLo']))\n",
    "    streets_df = streets_df.withColumn('EvenHi', get_street_number_udf(streets_df['EvenHi']))\n",
    "    \n",
    "    streets_df = streets_df.withColumn(\"BOROCODE\", streets_df[\"BOROCODE\"].cast(\"integer\"))\n",
    "    streets_df = streets_df.withColumn(\"OddLo\", streets_df[\"OddLo\"].cast(\"integer\"))\n",
    "    streets_df = streets_df.withColumn(\"OddHi\", streets_df[\"OddHi\"].cast(\"integer\"))\n",
    "    streets_df = streets_df.withColumn(\"EvenLo\", streets_df[\"EvenLo\"].cast(\"integer\"))\n",
    "    streets_df = streets_df.withColumn(\"EvenHi\", streets_df[\"EvenHi\"].cast(\"integer\"))\n",
    "    \n",
    "    streets_df = streets_df.repartition(5, 'BOROCODE')\n",
    "    streets_df = streets_df.alias('s')\n",
    "    return streets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "violations_df = get_violations_df(violations, spark)\n",
    "streets_df = get_streets_df(streets, spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5181"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "violations_df.count() # 5195, 5104, 4313"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "644780"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streets_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper(row):\n",
    "    if row['FULL_STREE'] == row['ST_LABEL']:\n",
    "        yield ( \n",
    "                (row['BOROCODE'], row[\"FULL_STREE\"] ), \n",
    "                [( row['EvenLo'],row['EvenHi'],row['OddLo'],row['OddHi'], row['PHYSICALID'] )] \n",
    "              ) \n",
    "    else:\n",
    "        yield ( \n",
    "                (row['BOROCODE'], row[\"FULL_STREE\"]), \n",
    "                [( row['EvenLo'],row['EvenHi'],row['OddLo'],row['OddHi'] ,row['PHYSICALID'] )] \n",
    "              ) \n",
    "        yield ( \n",
    "                (row['BOROCODE'], row[\"ST_LABEL\"]), \n",
    "                [( row['EvenLo'],row['EvenHi'],row['OddLo'],row['OddHi'], row['PHYSICALID'] ) ]\n",
    "              ) \n",
    "\n",
    "# broadcast(streets_df)\n",
    "streets_dict = streets_df.rdd.flatMap(mapper).reduceByKey(lambda x,y: x+y).collectAsMap()\n",
    "streets_dict_bc = sc.broadcast(streets_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------------+----+----------+\n",
      "|COUNTY|HOUSENUM|  STREETNAME|YEAR|PHYSICALID|\n",
      "+------+--------+------------+----+----------+\n",
      "|     1|      75|    BROAD ST|2015|        47|\n",
      "|     1|      75|    BROAD ST|2015|        47|\n",
      "|     1|     250|   ALBANY ST|2015|        56|\n",
      "|     1|      24|    STATE ST|2015|        61|\n",
      "|     1|      24|    STATE ST|2015|        61|\n",
      "|     1|      97|    PEARL ST|2015|        99|\n",
      "|     1|      95|    WATER ST|2015|       121|\n",
      "|     1|      33|WHITEHALL ST|2015|       128|\n",
      "|     1|       1|WHITEHALL ST|2015|       128|\n",
      "|     1|       0|WHITEHALL ST|2015|       128|\n",
      "+------+--------+------------+----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_val(borocode, street, housenum):\n",
    "    val = streets_dict_bc.value.get( (borocode, street) )\n",
    "    if val:\n",
    "        for item in val:\n",
    "            if housenum % 2 == 0:\n",
    "                if item[0] >= housenum and housenum <= item[1]:\n",
    "                    return item[4]\n",
    "            else:\n",
    "                if item[2] >= housenum and housenum <= item[3]:\n",
    "                    return item[4]     \n",
    "    return None\n",
    "\n",
    "get_val_udf = udf(get_val)\n",
    "\n",
    "matched_violations = violations_df.withColumn('PHYSICALID', get_val_udf(violations_df['v.COUNTY'], \n",
    "                                                                        violations_df['v.STREETNAME'], \n",
    "                                                                        violations_df['v.HOUSENUM']\n",
    "                                                          ))\n",
    "\n",
    "matched_violations = matched_violations.filter( matched_violations['PHYSICALID'].isNotNull() )\n",
    "matched_violations = matched_violations.withColumn(\"PHYSICALID\", matched_violations[\"PHYSICALID\"].cast(\"integer\"))\n",
    "matched_violations = matched_violations.orderBy(\"PHYSICALID\")\n",
    "matched_violations.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+----------+\n",
      "|PHYSICALID|YEAR|YEAR_COUNT|\n",
      "+----------+----+----------+\n",
      "|        47|2015|         2|\n",
      "|        56|2015|         1|\n",
      "|        61|2015|         2|\n",
      "|        99|2015|         1|\n",
      "|       121|2015|         1|\n",
      "|       128|2015|         3|\n",
      "|       135|2015|         4|\n",
      "|       140|2015|         1|\n",
      "|       141|2015|         1|\n",
      "|       158|2015|         7|\n",
      "+----------+----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "matched_violations = matched_violations.groupBy(\"PHYSICALID\", \"YEAR\").agg(count(\"*\").alias(\"YEAR_COUNT\"))\n",
    "matched_violations.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_violations.createOrReplaceTempView(\"matched_violations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+----------+----------+----------+\n",
      "|PHYSICALID|COUNT_2015|COUNT_2016|COUNT_2017|COUNT_2018|COUNT_2019|\n",
      "+----------+----------+----------+----------+----------+----------+\n",
      "|        47|         2|         0|         0|         0|         0|\n",
      "|        56|         1|         0|         0|         0|         0|\n",
      "|        61|         2|         0|         0|         0|         0|\n",
      "|        99|         1|         0|         0|         0|         0|\n",
      "|       121|         1|         0|         0|         0|         0|\n",
      "|       128|         3|         0|         0|         0|         0|\n",
      "|       135|         4|         0|         0|         0|         0|\n",
      "|       140|         1|         0|         0|         0|         0|\n",
      "|       141|         1|         0|         0|         0|         0|\n",
      "|       158|         7|         0|         0|         0|         0|\n",
      "+----------+----------+----------+----------+----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summaries = spark.sql(\n",
    "    \"select PHYSICALID, \" +\n",
    "    \"MAX(CASE WHEN (YEAR = 2015) THEN YEAR_COUNT ELSE 0 END) AS COUNT_2015, \" +\n",
    "    \"MAX(CASE WHEN (YEAR = 2016) THEN YEAR_COUNT ELSE 0 END) AS COUNT_2016, \" +\n",
    "    \"MAX(CASE WHEN (YEAR = 2017) THEN YEAR_COUNT ELSE 0 END) AS COUNT_2017, \" +\n",
    "    \"MAX(CASE WHEN (YEAR = 2018) THEN YEAR_COUNT ELSE 0 END) AS COUNT_2018, \" +\n",
    "    \"MAX(CASE WHEN (YEAR = 2019) THEN YEAR_COUNT ELSE 0 END) AS COUNT_2019  \" +\n",
    "    \"from matched_violations \" +\n",
    "    \"group by PHYSICALID \" +\n",
    "    \"order by PHYSICALID \"\n",
    ")\n",
    "summaries.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "getOLS_udf = udf(getOLS)\n",
    "summaries = summaries.withColumn('OLS_COEF', \n",
    "                getOLS_udf(array('COUNT_2015', 'COUNT_2016', 'COUNT_2017', 'COUNT_2018', 'COUNT_2019')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "streets_df = streets_df.select(col(\"s.PHYSICALID\")) \\\n",
    "                    .join(summaries, \"PHYSICALID\", how='left') \\\n",
    "                    .distinct() \\\n",
    "                    .orderBy(\"PHYSICALID\") \\\n",
    "\n",
    "streets_df = streets_df.withColumn(\"COUNT_2015\",coalesce(\"COUNT_2015\", lit(0))) \n",
    "streets_df = streets_df.withColumn(\"COUNT_2016\",coalesce(\"COUNT_2016\", lit(0))) \n",
    "streets_df = streets_df.withColumn(\"COUNT_2017\",coalesce(\"COUNT_2017\", lit(0))) \n",
    "streets_df = streets_df.withColumn(\"COUNT_2018\",coalesce(\"COUNT_2018\", lit(0))) \n",
    "streets_df = streets_df.withColumn(\"COUNT_2019\",coalesce(\"COUNT_2019\", lit(0))) \n",
    "streets_df = streets_df.withColumn(\"OLS_COEF\",  coalesce(\"OLS_COEF\", lit(0.0))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+----------+----------+----------+--------+\n",
      "|PHYSICALID|COUNT_2015|COUNT_2016|COUNT_2017|COUNT_2018|COUNT_2019|OLS_COEF|\n",
      "+----------+----------+----------+----------+----------+----------+--------+\n",
      "|         3|         0|         0|         0|         0|         0|     0.0|\n",
      "|         5|         0|         0|         0|         0|         0|     0.0|\n",
      "|         6|         0|         0|         0|         0|         0|     0.0|\n",
      "|         8|         0|         0|         0|         0|         0|     0.0|\n",
      "|        14|         0|         0|         0|         0|         0|     0.0|\n",
      "|        23|         0|         0|         0|         0|         0|     0.0|\n",
      "|        24|         0|         0|         0|         0|         0|     0.0|\n",
      "|        25|         0|         0|         0|         0|         0|     0.0|\n",
      "|        29|         0|         0|         0|         0|         0|     0.0|\n",
      "|        30|         0|         0|         0|         0|         0|     0.0|\n",
      "|        33|         0|         0|         0|         0|         0|     0.0|\n",
      "|        34|         0|         0|         0|         0|         0|     0.0|\n",
      "|        36|         0|         0|         0|         0|         0|     0.0|\n",
      "|        37|         0|         0|         0|         0|         0|     0.0|\n",
      "|        40|         0|         0|         0|         0|         0|     0.0|\n",
      "|        41|         0|         0|         0|         0|         0|     0.0|\n",
      "|        43|         0|         0|         0|         0|         0|     0.0|\n",
      "|        44|         0|         0|         0|         0|         0|     0.0|\n",
      "|        45|         0|         0|         0|         0|         0|     0.0|\n",
      "|        46|         0|         0|         0|         0|         0|     0.0|\n",
      "|        47|         2|         0|         0|         0|         0|     1.2|\n",
      "|        48|         0|         0|         0|         0|         0|     0.0|\n",
      "|        49|         0|         0|         0|         0|         0|     0.0|\n",
      "|        50|         0|         0|         0|         0|         0|     0.0|\n",
      "|        51|         0|         0|         0|         0|         0|     0.0|\n",
      "|        52|         0|         0|         0|         0|         0|     0.0|\n",
      "|        53|         0|         0|         0|         0|         0|     0.0|\n",
      "|        56|         1|         0|         0|         0|         0|     0.6|\n",
      "|        57|         0|         0|         0|         0|         0|     0.0|\n",
      "|        58|         0|         0|         0|         0|         0|     0.0|\n",
      "+----------+----------+----------+----------+----------+----------+--------+\n",
      "only showing top 30 rows\n",
      "\n",
      "--- 197.01361727714539 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "streets_df.show(30)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# streets_df.write.csv('TODO', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
