{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import traceback\n",
    "import time\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql.functions import col, udf, array, count\n",
    "from pyspark.sql.functions import broadcast,coalesce, lit\n",
    "from itertools import chain\n",
    "from pyspark.sql.functions import col, lit, when, isnull\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext()\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "streets = \"nyc_cscl.csv\"\n",
    "violations = \"nyc_parking_violation/*.csv\"\n",
    "\n",
    "# streets = \"hdfs:///tmp/bdm/nyc_cscl.csv\"\n",
    "# violations = \"hdfs:///tmp/bdm/nyc_parking_violations/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_upper(string):\n",
    "    if string is None:\n",
    "        return None\n",
    "    return string.strip().upper()\n",
    "\n",
    "def get_county_code(county):\n",
    "    if county is not None:\n",
    "        # Boro codes: 1 = MN, 2 = BX, 3 = BK, 4 = QN, 5 = SI\n",
    "        if county.startswith(\"M\") or county.startswith(\"N\"):\n",
    "            return 1\n",
    "        if county in ['BRONX', 'BX', 'PBX']:\n",
    "            return 2\n",
    "        if county in ['BK', 'K', 'KING', 'KINGS']:\n",
    "            return 3\n",
    "        if county.startswith('Q'):\n",
    "            return 4\n",
    "        if county == 'R' or county == 'ST':\n",
    "            return 5\n",
    "    return -1\n",
    "\n",
    "def get_year(string): \n",
    "    data_val = datetime.strptime(string.strip(), '%m/%d/%Y')    \n",
    "    return data_val.year\n",
    "\n",
    "def get_street_number(street_val):\n",
    "    if street_val is None:\n",
    "        return 0\n",
    "    if type(street_val) is int:\n",
    "        return street_val\n",
    "    elems = street_val.split(\"-\")\n",
    "    new_val = \"\".join(elems)\n",
    "    if new_val.isdigit():\n",
    "        return int(new_val)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def as_digit(val):\n",
    "    if val:\n",
    "        return int(val)\n",
    "    return val\n",
    "\n",
    "def getOLS(values):\n",
    "    import statsmodels.api as sm\n",
    "    X = sm.add_constant(np.arange(len(values)))\n",
    "    fit = sm.OLS(values, X).fit()\n",
    "    coef = fit.params[0]\n",
    "    return float(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_violations_df(violations_file, spark):\n",
    "    get_county_code_udf = udf(get_county_code)\n",
    "    get_street_number_udf = udf(get_street_number)\n",
    "    get_year_udf = udf(get_year)\n",
    "    to_upper_udf = udf(to_upper)\n",
    "    \n",
    "    violations_df = spark.read.csv(violations_file, header=True, inferSchema=True)\n",
    "\n",
    "    violations_df = violations_df.select(\"Violation County\", \"House Number\", \"Street Name\", \"Issue Date\")\n",
    "\n",
    "    violations_df = violations_df.filter((violations_df['Violation County'].isNotNull()) \n",
    "                                         & (violations_df['House Number'].isNotNull()) \n",
    "                                         & (violations_df['Street Name'].isNotNull()) \n",
    "                                         & (violations_df['Issue Date'].isNotNull())\n",
    "                                        )\n",
    "\n",
    "    violations_df = violations_df.withColumn('Violation County', get_county_code_udf(violations_df['Violation County']))\n",
    "    violations_df = violations_df.withColumn('House Number', get_street_number_udf(violations_df['House Number']))\n",
    "    violations_df = violations_df.withColumn('Street Name', to_upper_udf(violations_df['Street Name']))\n",
    "    violations_df = violations_df.withColumn('Issue Date', get_year_udf(violations_df['Issue Date']))\n",
    "\n",
    "    violations_df = violations_df.withColumnRenamed(\"Violation County\",\"COUNTY\")\n",
    "    violations_df = violations_df.withColumnRenamed(\"House Number\",\"HOUSENUM\")\n",
    "    violations_df = violations_df.withColumnRenamed(\"Street Name\",\"STREETNAME\")\n",
    "    violations_df = violations_df.withColumnRenamed(\"Issue Date\",\"YEAR\")\n",
    "\n",
    "    violations_df = violations_df.where(violations_df.YEAR.isin(list(range(2015,2020))))\n",
    "    violations_df = violations_df.repartition(5,'COUNTY')\n",
    "    violations_df = violations_df.alias('v')\n",
    "    return violations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_streets_df(streets_file, spark):\n",
    "    get_street_number_udf = udf(get_street_number)\n",
    "    to_upper_udf = udf(to_upper)\n",
    "    as_digit_udf = udf(as_digit)\n",
    "    \n",
    "    streets_df = spark.read.csv(streets_file, header=True, inferSchema=True)\n",
    "\n",
    "    streets_df = streets_df.select(\"PHYSICALID\",\"BOROCODE\", \"FULL_STREE\", \"ST_LABEL\",\"L_LOW_HN\", \"L_HIGH_HN\", \n",
    "                                   \"R_LOW_HN\", \"R_HIGH_HN\")\n",
    "\n",
    "    streets_df = streets_df.withColumn('BOROCODE', as_digit_udf(streets_df['BOROCODE']))\n",
    "    streets_df = streets_df.withColumn('FULL_STREE', to_upper_udf(streets_df['FULL_STREE']))\n",
    "    streets_df = streets_df.withColumn('ST_LABEL',   to_upper_udf(streets_df['ST_LABEL']))\n",
    "    streets_df = streets_df.withColumn('L_LOW_HN',  get_street_number_udf(streets_df['L_LOW_HN']))\n",
    "    streets_df = streets_df.withColumn('L_HIGH_HN', get_street_number_udf(streets_df['L_HIGH_HN']))\n",
    "    streets_df = streets_df.withColumn('R_LOW_HN',  get_street_number_udf(streets_df['R_LOW_HN']))\n",
    "    streets_df = streets_df.withColumn('R_HIGH_HN', get_street_number_udf(streets_df['R_HIGH_HN']))\n",
    "\n",
    "    streets_df = streets_df.withColumnRenamed(\"L_LOW_HN\",\"OddLo\")\n",
    "    streets_df = streets_df.withColumnRenamed(\"L_HIGH_HN\",\"OddHi\")\n",
    "    streets_df = streets_df.withColumnRenamed(\"R_LOW_HN\",\"EvenLo\")\n",
    "    streets_df = streets_df.withColumnRenamed(\"R_HIGH_HN\",\"EvenHi\")\n",
    "    \n",
    "    streets_df = streets_df.repartition(5, 'BOROCODE')\n",
    "    streets_df = streets_df.alias('s')\n",
    "    return streets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "violations_df = get_violations_df(violations, spark)\n",
    "streets_df = get_streets_df(streets, spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper(row):\n",
    "    if row['FULL_STREE'] == row['ST_LABEL']:\n",
    "        yield ( \n",
    "                (row['BOROCODE'], row[\"FULL_STREE\"] ), \n",
    "                [( row['EvenLo'],row['EvenHi'],row['OddLo'],row['OddHi'], row['PHYSICALID'] )] \n",
    "              ) \n",
    "    else:\n",
    "        yield ( \n",
    "                (row['BOROCODE'], row[\"FULL_STREE\"]), \n",
    "                [( row['EvenLo'],row['EvenHi'],row['OddLo'],row['OddHi'] ,row['PHYSICALID'] )] \n",
    "              ) \n",
    "        yield ( \n",
    "                (row['BOROCODE'], row[\"ST_LABEL\"]), \n",
    "                [( row['EvenLo'],row['EvenHi'],row['OddLo'],row['OddHi'], row['PHYSICALID'] ) ]\n",
    "              ) \n",
    "\n",
    "streets_dict = streets_df.rdd.flatMap(mapper).reduceByKey(lambda x,y: x+y).collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val(borocode, street, housenum):\n",
    "    val = streets_dict.get( (borocode, street) )\n",
    "    if val:\n",
    "        for item in val:\n",
    "            if int(housenum) % 2 == 0:\n",
    "                if int(item[0]) >= int(housenum )and int(housenum) <= int(item[1]):\n",
    "                    return item[4]\n",
    "            else:\n",
    "                if int(item[2]) >= int(housenum) and int(housenum) <= int(item[3]):\n",
    "                    return item[4]      \n",
    "    return None\n",
    "\n",
    "get_val_udf = udf(get_val)\n",
    "\n",
    "violations_2 = violations_df.withColumn('PHYSICALID', get_val_udf(violations_df['v.County'], \n",
    "                                                          violations_df['v.STREETNAME'], violations_df['v.HOUSENUM']\n",
    "                                                          ))\n",
    "\n",
    "violations_2 = violations_2.filter( violations_2['PHYSICALID'].isNotNull() )\n",
    "# violations_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "violations_2 = violations_2.groupBy(\"PHYSICALID\", \"YEAR\").agg(count(\"*\").alias(\"YEAR_COUNT\"))\n",
    "# violations_2.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "violations_2.createOrReplaceTempView(\"violations2_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = spark.sql(\n",
    "    \"select PHYSICALID, \" +\n",
    "    \"MAX(CASE WHEN (YEAR = 2015) THEN YEAR_COUNT ELSE 0 END) AS COUNT_2015, \" +\n",
    "    \"MAX(CASE WHEN (YEAR = 2016) THEN YEAR_COUNT ELSE 0 END) AS COUNT_2016, \" +\n",
    "    \"MAX(CASE WHEN (YEAR = 2017) THEN YEAR_COUNT ELSE 0 END) AS COUNT_2017, \" +\n",
    "    \"MAX(CASE WHEN (YEAR = 2018) THEN YEAR_COUNT ELSE 0 END) AS COUNT_2018, \" +\n",
    "    \"MAX(CASE WHEN (YEAR = 2019) THEN YEAR_COUNT ELSE 0 END) AS COUNT_2019  \" +\n",
    "    \"from violations2_results \" +\n",
    "    \"group by PHYSICALID \" +\n",
    "    \"order by PHYSICALID \"\n",
    ")\n",
    "# summaries.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "getOLS_udf = udf(getOLS)\n",
    "summaries = summaries.withColumn('OLS_COEF', \n",
    "                getOLS_udf(array('COUNT_2015', 'COUNT_2016', 'COUNT_2017', 'COUNT_2018', 'COUNT_2019')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+----------+----------+----------+------------------+\n",
      "|PHYSICALID|COUNT_2015|COUNT_2016|COUNT_2017|COUNT_2018|COUNT_2019|          OLS_COEF|\n",
      "+----------+----------+----------+----------+----------+----------+------------------+\n",
      "|    100016|         2|         0|         0|         0|         0|               1.2|\n",
      "|    100070|         5|         0|         0|         0|         0|               3.0|\n",
      "|    100106|         1|         0|         0|         0|         0|               0.6|\n",
      "|    100172|         1|         0|         0|         0|         0|               0.6|\n",
      "|    100181|         2|         0|         0|         0|         0|               1.2|\n",
      "|    100272|         1|         0|         0|         0|         0|               0.6|\n",
      "|    100322|         2|         0|         0|         0|         0|               1.2|\n",
      "|    100735|         1|         0|         0|         0|         0|               0.6|\n",
      "|    100921|         1|         0|         0|         0|         0|               0.6|\n",
      "|    100983|         1|         0|         0|         0|         0|               0.6|\n",
      "|    101153|         4|         0|         0|         0|         0|               2.4|\n",
      "|    101210|         1|         0|         0|         0|         0|               0.6|\n",
      "|    101317|         1|         0|         0|         0|         0|               0.6|\n",
      "|    101323|         1|         0|         0|         0|         0|               0.6|\n",
      "|    101328|         3|         0|         0|         0|         0|1.7999999999999998|\n",
      "|    101329|         1|         0|         0|         0|         0|               0.6|\n",
      "|    101371|         1|         0|         0|         0|         0|               0.6|\n",
      "|    101390|         4|         0|         0|         0|         0|               2.4|\n",
      "|    101401|         2|         0|         0|         0|         0|               1.2|\n",
      "|      1015|        16|         0|         0|         0|         0|               9.6|\n",
      "+----------+----------+----------+----------+----------+----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "--- 19.933086395263672 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "summaries.show()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# streets_df.write.csv('TODO', header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
